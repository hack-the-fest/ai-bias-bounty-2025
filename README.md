Problem Addressed : Detecting Bias in datasets and proposing solutions to mitigate the bias
Summary of model approach and fairness considerations: Ive trained the dataset on different models(Logistic Regression, Random Forest Classifier, XGBClassifier, Custom Neural Network) and chose the best performing model which was the Logistic Regression model. The model was chosen after evaluating the precision, accuracy and recall scores of all the models. To detect bias, I used the IBM AIF360 tool to calculate 'Equal Oppurtunities Difference', 'Average Odds Difference', 'Theil Index', 'Statistical Parity Difference', 'Disparate Impact'. I also considered group-wise approval rates and intersection fairness to arrive at the final conclusion. 
Used libraries : scikit-learn, numpy, pandas, matplotlib, seaborn, tensorflow, aif360, shap, lime
Instructions to run project: Ive provided a ipynb file which can be run line by line.
Link for Demo Video: https://drive.google.com/drive/folders/1im4nN8IIzT_C3YQWD1duaHXTOX9VuMim?usp=sharing